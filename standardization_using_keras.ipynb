{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFQ3s6BFzWrA2+JGWPl2Hd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gerald-mut/Keras-intro/blob/main/standardization_using_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5sSHuwo13gkr"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\n",
        "#reshape dataset to have a single channel\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
        "\n",
        "#confirm scale of pixels\n",
        "print('Train min=%.3f, max=%.3f' % (trainX.min(), trainX.max()))\n",
        "print('Test min=%.3f, max=%.3f' % (testX.min(), testX.max()))\n",
        "\n",
        "# create generator (1.0/255.0 = 0.003921568627451)\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# prepare a iterators to scale images\n",
        "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
        "\n",
        "#confirm that scaling works\n",
        "batchX, batchY = train_iterator.__next__()\n",
        "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JVDwcFQa31R",
        "outputId": "5dba6902-14d4-4289-ec65-e08a7589c2ab"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train min=0.000, max=255.000\n",
            "Test min=0.000, max=255.000\n",
            "Batches train=938, test=157\n",
            "Batch shape=(64, 28, 28, 1), min=0.000, max=1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of standardizing a image dataset\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# load dataset\n",
        "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
        "# reshape dataset to have a single channel\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
        "# report pixel means and standard deviations\n",
        "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (trainX.mean(), trainX.std(),\n",
        "testX.mean(), testX.std()))\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(trainX)\n",
        "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\n",
        "# demonstrate effect on a single batch of samples\n",
        "iterator = datagen.flow(trainX, trainy, batch_size=64)\n",
        "# get a batch\n",
        "batchX, batchy = iterator.__next__()\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())\n",
        "# demonstrate effect on entire training dataset\n",
        "iterator = datagen.flow(trainX, trainy, batch_size=len(trainX), shuffle=False)\n",
        "# get a batch\n",
        "batchX, batchy = iterator.__next__()\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM4lEAvA5Efm",
        "outputId": "9ce658cb-c28b-4c45-940e-2bb2bea1964b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics train=33.318 (78.567), test=33.791 (79.172)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3263743718.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Generator mean=33.318, std=78.567\n",
            "(64, 28, 28, 1) 0.014693455 1.0200273\n",
            "(60000, 28, 28, 1) -3.4560264e-07 0.9999998\n"
          ]
        }
      ]
    }
  ]
}